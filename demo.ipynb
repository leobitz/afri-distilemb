{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840d80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import BertModel\n",
    "from distill_emb import DistillEmbSmall\n",
    "from config import BertConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, RwkvConfig, RwkvModel, AutoModel\n",
    "from tokenizer import CharTokenizer\n",
    "from knn_classifier import KNNTextClassifier\n",
    "from data_loader import load_sentiment\n",
    "from data_loader import load_news_dataset\n",
    "import pandas as pd\n",
    "from retrieval import build_json_pairs, top1_accuracy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf287ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_chars=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c07d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(charset_file_path='tokenizer/charset.json',\n",
    "                          max_word_length=num_input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0870d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=9,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    pad_token_id=0,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    classifier_dropout=None,\n",
    "    embedding_type=\"distill\",  # 'distilemb', 'fasttext'\n",
    "    encoder_type='lstm',\n",
    "    num_input_chars=num_input_chars,  # number of characters in each token\n",
    "    char_vocab_size=tokenizer.char_vocab_size\n",
    ")\n",
    "model = BertModel(config)\n",
    "# input ids with (B, S, N)\n",
    "char_input = torch.randint(0, config.num_input_chars, (1, 10, config.num_input_chars))\n",
    "# input ids with (B, S, N)\n",
    "\n",
    "inputs = {\n",
    "    \"input_ids\": char_input,\n",
    "    \"attention_mask\":torch.tensor([[1] * char_input.size(1)]),  # attention mask for each token\n",
    "    \"token_type_ids\": torch.tensor([[0] * char_input.size(1)]),  # token type ids for each token\n",
    "}\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0e8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb = DistillEmbSmall(config)\n",
    "path = \"logs/distill_emb_v0/distill_emb_v0-epoch=95-epoch_val_loss=0.06.ckpt\"\n",
    "if os.path.exists(path):\n",
    "    state_dict = torch.load(path, map_location='cpu')['state_dict']\n",
    "    # remove 'model.' prefix from state_dict keys\n",
    "    state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "    distill_emb.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(f\"Model checkpoint {path} not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f387f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillEmbSmall(\n",
       "  (embedding): Embedding(1518, 64)\n",
       "  (conv1): Conv1d(12, 128, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (conv3): Conv1d(256, 384, kernel_size=(5,), stride=(1,))\n",
       "  (conv4): Conv1d(384, 512, kernel_size=(4,), stride=(1,))\n",
       "  (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (output_layer): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (activation): ReLU()\n",
       "  (tanh): Tanh()\n",
       "  (norm0): LayerNorm((12, 64), eps=1e-05, elementwise_affine=True)\n",
       "  (norm1): LayerNorm((128, 30), eps=1e-05, elementwise_affine=True)\n",
       "  (norm2): LayerNorm((256, 13), eps=1e-05, elementwise_affine=True)\n",
       "  (norm3): LayerNorm((384, 4), eps=1e-05, elementwise_affine=True)\n",
       "  (norm4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (output_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f0f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer('hello world', add_special_tokens=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af523e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_emb(out['input_ids'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f0aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb = distill_emb.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51528542",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNNTextClassifier(tokenizer, model=distill_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e484af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105862 rows from sentiment.parquet columns Index(['text', 'label', 'lang', 'split'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df, classes = load_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5227365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(1000, random_state=42)\n",
    "test_df = df.drop(train_df.index).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7589f008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4007096171802055,\n",
       " 0.41000000000000003,\n",
       " {'ma': {'f1': 0.4608843537414966, 'acc': 0.5},\n",
       "  'sw': {'f1': 0.4897385620915033, 'acc': 0.5},\n",
       "  'dz': {'f1': 0.33730158730158727, 'acc': 0.3333333333333333},\n",
       "  'kr': {'f1': 0.6439393939393939, 'acc': 0.6363636363636364},\n",
       "  'pt': {'f1': 0.2040816326530612, 'acc': 0.14285714285714285},\n",
       "  'twi': {'f1': 0.1, 'acc': 0.25},\n",
       "  'yo': {'f1': 0.3956043956043956, 'acc': 0.38461538461538464},\n",
       "  'pcm': {'f1': 0.0, 'acc': 0.0},\n",
       "  'ha': {'f1': 0.4800000000000001, 'acc': 0.4},\n",
       "  'am': {'f1': 0.6, 'acc': 0.6},\n",
       "  'ts': {'f1': 0.0, 'acc': 0.0},\n",
       "  'ig': {'f1': 0.3333333333333333, 'acc': 0.5},\n",
       "  'tg': {'f1': 0.0, 'acc': 0.0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=None, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bonadossou/afrolm_active_learning\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "xmodel = AutoModel.from_pretrained(model_name)\n",
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        embs = self.model(**kwargs).last_hidden_state\n",
    "        return embs\n",
    "\n",
    "wrapper_model = Wrapper(xmodel).to('cuda').eval()\n",
    "classifier = KNNTextClassifier(tokenizer=tok, model=wrapper_model)\n",
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=wrapper_model, tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f2459c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30809 rows from masakhanews.parquet columns Index(['label', 'headline', 'text', 'headline_text', 'url', 'lang', 'split'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data, classes = load_news_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34322e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.sample(1000, random_state=42)\n",
    "test_df = data.drop(train_df.index).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2893e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3351587301587302,\n",
       " 0.3700000000000001,\n",
       " {'orm': {'f1': 0.16049382716049382, 'acc': 0.2222222222222222},\n",
       "  'xho': {'f1': 0.4821428571428571, 'acc': 0.5},\n",
       "  'eng': {'f1': 0.24603174603174605, 'acc': 0.26666666666666666},\n",
       "  'tir': {'f1': 0.3333333333333333, 'acc': 0.4},\n",
       "  'som': {'f1': 0.36666666666666664, 'acc': 0.4},\n",
       "  'hau': {'f1': 0.11904761904761904, 'acc': 0.14285714285714285},\n",
       "  'pcm': {'f1': 0.2833333333333334, 'acc': 0.3333333333333333},\n",
       "  'lug': {'f1': 0.19047619047619047, 'acc': 0.3333333333333333},\n",
       "  'lin': {'f1': 0.8333333333333334, 'acc': 0.8333333333333334},\n",
       "  'ibo': {'f1': 0.6666666666666666, 'acc': 0.75},\n",
       "  'fra': {'f1': 0.34285714285714286, 'acc': 0.4},\n",
       "  'sna': {'f1': 0.0, 'acc': 0.0},\n",
       "  'run': {'f1': 0.4444444444444444, 'acc': 0.3333333333333333},\n",
       "  'swa': {'f1': 0.8, 'acc': 0.8},\n",
       "  'yor': {'f1': 0.16, 'acc': 0.2},\n",
       "  'amh': {'f1': 1.0, 'acc': 1.0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=None, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 10 per language\n",
    "train_df = data[data['split'] == 'train'].groupby('lang').apply(lambda x: x.sample(200, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs = ['amh', 'hau', 'ibo', 'lug', 'pcm','yor']\n",
    "# train_df = train_df[train_df['lang'].isin(langs)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75066ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['headline'].sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = build_json_pairs(train_df, model_name=\"Davlan/afro-xlmr-large\",\n",
    "#                  n_samples=200, m_candidates=100, k_top=9, text_col=\"text\", headline_col=\"headline\")\n",
    "# # save to json file\n",
    "# import json\n",
    "# with open('news_result.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result, f, indent=4, ensure_ascii=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46753293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = build_json_pairs(train_df, model_name=\"Davlan/afro-xlmr-large\",\n",
    "#                  n_samples=200, m_candidates=100, k_top=9, text_col=\"headline\", headline_col=\"text\")\n",
    "# # save to json file\n",
    "# import json\n",
    "# with open('headline_result.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result, f, indent=4, ensure_ascii=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('news_result.json')\n",
    "d = df.to_dict(orient='records')\n",
    "top1_accuracy(d, batch_size=32, model=xmodel, tokenizer=tok)\n",
    "# top1_accuracy(d, batch_size=32, model=distill_emb, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext_model import FastTextModel\n",
    "fasttext_model = FastTextModel(file_path='embeddings/afriberta/afriberta.vec')\n",
    "# fasttext_model.embedding.weight.requires_grad = False  # freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a441e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
