{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d80c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import BertModel\n",
    "from distill_emb import DistillEmbSmall, DistillEmb\n",
    "from config import DistillModelConfig, DistillEmbConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, RwkvConfig, RwkvModel, AutoModel\n",
    "from tokenizer import CharTokenizer\n",
    "from knn_classifier import KNNTextClassifier\n",
    "from data_loader import load_sentiment\n",
    "from data_loader import load_news_dataset\n",
    "import pandas as pd\n",
    "from retrieval import build_json_pairs, top1_accuracy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf287ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_chars=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07d547",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CharTokenizer(charset_file_path='tokenizer/charset.json',\n",
    "                          max_word_length=num_input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870d762",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistillModelConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=9,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    pad_token_id=0,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    classifier_dropout=None,\n",
    "    embedding_type=\"distill\",  # 'distilemb', 'fasttext'\n",
    "    encoder_type='bert',\n",
    "    num_input_chars=num_input_chars,  # number of characters in each token\n",
    "    char_vocab_size=tokenizer.char_vocab_size,\n",
    "    distil_config=DistillEmbConfig(\n",
    "        num_input_chars=tokenizer.max_word_length,  # number of characters in each token\n",
    "        char_vocab_size=tokenizer.char_vocab_size,\n",
    "        size=\"small\",\n",
    "        distill_dropout=0.1,\n",
    "    )\n",
    ")\n",
    "model = BertModel(config)\n",
    "# input ids with (B, S, N)\n",
    "char_input = torch.randint(0, config.num_input_chars, (1, 10, config.num_input_chars))\n",
    "# input ids with (B, S, N)\n",
    "print(\"char_input shape:\", char_input.shape)\n",
    "inputs = {\n",
    "    \"input_ids\": char_input,\n",
    "    \"attention_mask\":torch.tensor([[1] * char_input.size(1)]),  # attention mask for each token\n",
    "    \"token_type_ids\": torch.tensor([[0] * char_input.size(1)]),  # token type ids for each token\n",
    "}\n",
    "outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb = DistillEmb(config.distil_config)\n",
    "path = \"logs/distill_emb_v0/distill_emb_v0-epoch=95-epoch_val_loss=0.06.ckpt\"\n",
    "if os.path.exists(path):\n",
    "    state_dict = torch.load(path, map_location='cpu')['state_dict']\n",
    "    # remove 'model.' prefix from state_dict keys\n",
    "    state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "    distill_emb.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(f\"Model checkpoint {path} not found. Please check the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f387f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0f39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = tokenizer('hello world', add_special_tokens=False, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af523e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb(out['input_ids'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0aeb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "distill_emb = distill_emb.to('cuda').eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51528542",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KNNTextClassifier(tokenizer, model=distill_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e484af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, classes = load_sentiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5227365",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.sample(1000, random_state=42)\n",
    "test_df = df.drop(train_df.index).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589f008",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=None, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bonadossou/afrolm_active_learning\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "xmodel = AutoModel.from_pretrained(model_name)\n",
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        embs = self.model(**kwargs).last_hidden_state\n",
    "        return embs\n",
    "\n",
    "wrapper_model = Wrapper(xmodel).to('cuda').eval()\n",
    "classifier = KNNTextClassifier(tokenizer=tok, model=wrapper_model)\n",
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=wrapper_model, tokenizer=tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2459c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, classes = load_news_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34322e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.sample(1000, random_state=42)\n",
    "test_df = data.drop(train_df.index).sample(100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2893e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.classifiy(train_df=train_df, test_df=test_df, k=5, batch_size=32, model=None, tokenizer=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 10 per language\n",
    "train_df = data[data['split'] == 'train'].groupby('lang').apply(lambda x: x.sample(200, random_state=42)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langs = ['amh', 'hau', 'ibo', 'lug', 'pcm','yor']\n",
    "# train_df = train_df[train_df['lang'].isin(langs)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75066ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['headline'].sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = build_json_pairs(train_df, model_name=\"Davlan/afro-xlmr-large\",\n",
    "#                  n_samples=200, m_candidates=100, k_top=9, text_col=\"text\", headline_col=\"headline\")\n",
    "# # save to json file\n",
    "# import json\n",
    "# with open('news_result.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result, f, indent=4, ensure_ascii=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46753293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = build_json_pairs(train_df, model_name=\"Davlan/afro-xlmr-large\",\n",
    "#                  n_samples=200, m_candidates=100, k_top=9, text_col=\"headline\", headline_col=\"text\")\n",
    "# # save to json file\n",
    "# import json\n",
    "# with open('headline_result.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(result, f, indent=4, ensure_ascii=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d75e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('news_result.json')\n",
    "d = df.to_dict(orient='records')\n",
    "top1_accuracy(d, batch_size=32, model=xmodel, tokenizer=tok)\n",
    "# top1_accuracy(d, batch_size=32, model=distill_emb, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7f662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fasttext_model import FastTextModel\n",
    "fasttext_model = FastTextModel(file_path='embeddings/afriberta/afriberta.vec')\n",
    "# fasttext_model.embedding.weight.requires_grad = False  # freeze the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a441e21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
