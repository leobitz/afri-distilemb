{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bb64b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert import BertModel\n",
    "from distill_emb import DistillEmb\n",
    "from config import DistillModelConfig, DistillEmbConfig\n",
    "import torch\n",
    "from transformers import AutoTokenizer, RwkvConfig, RwkvModel, AutoModel\n",
    "from tokenizer import CharTokenizer\n",
    "from knn_classifier import KNNTextClassifier\n",
    "from data_loader import load_sentiment\n",
    "from data_loader import load_news_dataset\n",
    "import pandas as pd\n",
    "from retrieval import build_json_pairs, top1_accuracy\n",
    "import os\n",
    "from fasttext_model import FastTextModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981afb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_chars=12\n",
    "tokenizer = CharTokenizer(charset_file_path='tokenizer/charset.json',\n",
    "                          max_word_length=num_input_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d784e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistillModelConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=9,\n",
    "    num_attention_heads=8,\n",
    "    intermediate_size=3072,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=2,\n",
    "    pad_token_id=0,\n",
    "    position_embedding_type=\"absolute\",\n",
    "    use_cache=True,\n",
    "    classifier_dropout=None,\n",
    "    embedding_type=\"distill\",  # 'distilemb', 'fasttext'\n",
    "    encoder_type='bert',\n",
    "    num_input_chars=num_input_chars,  # number of characters in each token\n",
    "    char_vocab_size=tokenizer.char_vocab_size,\n",
    "    distil_config=DistillEmbConfig(\n",
    "        num_input_chars=tokenizer.max_word_length,  # number of characters in each token\n",
    "        char_vocab_size=tokenizer.char_vocab_size,\n",
    "        size=\"small\",\n",
    "        distill_dropout=0.1,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ded031a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model=None, tokenizer=None, pipeline=None):\n",
    "    # assert that either pipeline or model and tokenizer are provided\n",
    "    if pipeline is None:\n",
    "        assert model is not None and tokenizer is not None, \"Either pipeline or model and tokenizer must be provided.\"\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        classifier = KNNTextClassifier(tokenizer=tokenizer, model=model, pipeline=pipeline)\n",
    "\n",
    "        df, classes = load_sentiment()\n",
    "        # Sample equal amount for each language in the 'lang' column\n",
    "        min_count = min(df['lang'].value_counts().min(), 250)\n",
    "        sent_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "        sent_train_df = sent_df.sample(frac=0.8, random_state=42)\n",
    "        sent_test_df = sent_df.drop(sent_train_df.index)\n",
    "        print(f\"train shape: {sent_train_df.shape}, test shape: {sent_test_df.shape}\")\n",
    "        sent_f1, sent_acc, sent_per_lang, sent_test_df = classifier.classifiy(train_df=sent_train_df, test_df=sent_test_df, k=5, batch_size=32, model=None, tokenizer=None)\n",
    "\n",
    "        df, classes = load_news_dataset()\n",
    "        min_count = min(df['lang'].value_counts().min(), 250)\n",
    "        news_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n",
    "        news_train_df = news_df.sample(frac=0.8, random_state=42)\n",
    "        news_test_df = news_df.drop(news_train_df.index)\n",
    "        print(f\"train shape: {news_train_df.shape}, test shape: {news_test_df.shape}\")\n",
    "        news_f1, news_acc, news_per_lang, news_test_df = classifier.classifiy(train_df=news_train_df, test_df=news_test_df, k=5, batch_size=32, model=None, tokenizer=None)\n",
    "\n",
    "        df = pd.read_json('downstream-data/news_result.json')\n",
    "        d = df.to_dict(orient='records')\n",
    "        ret_acc, _, ret_per_lang = top1_accuracy(d, batch_size=32, model=model, tokenizer=tokenizer, pipeline=pipeline)\n",
    "    \n",
    "    return sent_acc, news_acc, ret_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc257006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint logs/distill_emb_v0/distill_emb_v0-epoch=136-epoch_val_loss=0.27x.ckpt not found. Please check the path.\n",
      "Loaded 105862 rows from sentiment.parquet columns Index(['text', 'label', 'lang', 'split'], dtype='object')\n",
      "train shape: (2800, 4), test shape: (700, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5878/3998590600.py:12: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sent_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30809 rows from masakhanews.parquet columns Index(['label', 'headline', 'text', 'headline_text', 'url', 'lang', 'split'], dtype='object')\n",
      "train shape: (3200, 7), test shape: (800, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5878/3998590600.py:20: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  news_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0141dff8764a48bcac2cb67b72251af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.4085714285714286, 0.42375, 0.12375)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distill_emb = DistillEmb(config.distil_config)\n",
    "path = \"logs/distill_emb_v0/distill_emb_v0-epoch=136-epoch_val_loss=0.27.ckpt\"\n",
    "if os.path.exists(path):\n",
    "    state_dict = torch.load(path, map_location='cpu')['state_dict']\n",
    "    # remove 'model.' prefix from state_dict keys\n",
    "    state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}\n",
    "    distill_emb.load_state_dict(state_dict)\n",
    "else:\n",
    "    print(f\"Model checkpoint {path} not found. Please check the path.\")\n",
    "\n",
    "distill_emb = distill_emb.to('cuda').eval()\n",
    "eval_model(distill_emb, tokenizer)\n",
    "# (0.45428571428571435, 0.51125, 0.1453125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9ff9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['885388', '512']\n",
      "['0.44083', '-0.42965', '0.95103', '-0.36828', '0.13706', '-0.56783', '0.7566', '-0.32185', '-0.47046', '0.54537', '-0.56555', '0.2719', '-0.27293', '-0.44355', '0.34395', '-0.24223', '0.78267', '-0.20981', '0.1417', '-0.43735', '-0.32911', '-0.069809', '0.25748', '0.11058', '-0.069525', '-0.47525', '0.4594', '-0.32668', '-0.15052', '-0.24592', '0.56542', '0.56852', '-0.59562', '-0.088829', '-0.02957', '0.025426', '-0.98067', '-0.64689', '0.37806', '0.23468', '0.21492', '-0.64253', '-0.13397', '-0.15448', '-0.33669', '-0.40539', '-0.42543', '-0.27762', '-0.19928', '0.44423', '0.13137', '0.17243', '0.50332', '-0.0012694', '-0.43177', '-0.29488', '0.7005', '0.12004', '0.39133', '-0.46595', '-0.055164', '-0.436', '-0.06664', '-0.51853', '-0.072684', '0.65205', '0.46941', '-0.89723', '0.14686', '-0.20592', '-0.40505', '-0.01811', '0.097973', '-0.24806', '-0.4467', '-0.2761', '0.61319', '-0.14258', '0.21318', '-0.22695', '0.31721', '0.18999', '-0.22422', '-0.050228', '0.35096', '0.70579', '0.13674', '-0.13447', '-0.063726', '-0.68435', '-0.87118', '-0.48077', '-0.28902', '-0.18712', '0.16907', '-0.30936', '-0.75292', '0.53078', '0.16952', '-0.17932', '-0.17042', '0.12586', '0.2092', '-0.20871', '0.18975', '-0.013418', '0.26653', '-0.16411', '0.52694', '0.2989', '0.10886', '-0.69887', '-1.1325', '-0.67691', '0.52901', '-0.58277', '0.48798', '0.14438', '0.40109', '-0.27955', '0.19421', '0.20987', '0.16962', '-0.3157', '0.45623', '0.68729', '0.56357', '-0.23943', '-0.049305', '0.42883', '-0.12513', '-0.22046', '-0.60326', '0.4627', '-0.15814', '0.0093243', '-0.17992', '-0.15173', '-0.10563', '0.78339', '-0.43941', '0.020949', '0.38692', '-0.24524', '-0.097647', '-0.0050123', '0.5133', '-0.12955', '-0.0454', '-0.057339', '-0.38272', '-0.88285', '-0.07916', '-0.75182', '0.15069', '0.1115', '-0.042528', '0.20281', '0.43346', '0.52959', '0.25245', '0.2162', '-0.706', '-0.24858', '0.82984', '-0.048864', '0.60263', '0.30161', '0.15172', '0.37449', '0.4133', '-0.36307', '0.46637', '0.24296', '0.087675', '-0.79497', '-0.42091', '0.30322', '0.12936', '0.044028', '-0.3623', '-0.14833', '-0.34286', '-0.61683', '0.20814', '0.17443', '-0.15097', '0.6874', '-0.12133', '-0.29947', '0.44862', '-0.068371', '-0.65662', '0.72638', '0.0094986', '-0.45604', '0.29824', '0.64156', '0.042655', '-0.43605', '0.17983', '-0.93434', '0.57246', '-0.46323', '0.076615', '-0.12164', '-0.42629', '-0.56373', '0.6526', '-0.69678', '0.34953', '-0.34046', '0.1494', '0.083166', '-0.51939', '0.31278', '-0.61364', '-0.62782', '-0.15958', '0.69402', '0.661', '0.35424', '-0.14759', '-0.67349', '0.59464', '0.24684', '-0.76901', '0.21409', '0.40943', '-0.073716', '-0.12128', '0.19301', '0.87718', '-0.1225', '-0.055964', '0.28069', '-0.21214', '-0.34244', '0.18434', '0.68242', '0.64773', '0.41457', '-0.26379', '-0.35366', '0.73814', '0.64158', '-0.24523', '0.36487', '0.45705', '0.4301', '-0.074767', '0.31235', '-0.51453', '-0.46387', '0.2982', '-0.40816', '0.047945', '-0.60584', '-0.10499', '-0.013342', '0.25288', '0.21557', '-0.58027', '0.25719', '0.14011', '-0.22574', '-0.66189', '-0.22583', '0.11992', '0.22454', '-0.18495', '-0.12449', '0.87813', '-0.28235', '0.34491', '0.36608', '-0.57948', '0.49411', '0.30249', '0.099968', '0.47039', '-0.25025', '0.68865', '-0.12775', '-0.087566', '0.040219', '0.063578', '-0.86156', '0.47836', '0.14055', '-0.09122', '0.034907', '0.36123', '-0.23305', '0.25345', '0.057701', '0.56531', '-1.0266', '0.81674', '0.1768', '0.50182', '-0.80934', '0.084152', '-0.089239', '-0.26732', '0.90272', '-0.26453', '0.0090403', '-0.056532', '-0.13489', '0.20268', '-0.69619', '0.82666', '-0.0068695', '0.54287', '0.065809', '0.34087', '-0.054885', '0.3946', '-0.13411', '-0.071401', '0.18729', '-0.47447', '-0.44925', '-0.21742', '-0.34871', '-0.78663', '0.18417', '-0.42705', '-0.10012', '0.22614', '0.065867', '-0.39841', '0.13257', '-0.46482', '0.0071942', '-0.35086', '-0.7642', '0.12494', '-0.22263', '-0.35904', '-0.059766', '0.32477', '0.28244', '-0.84597', '0.49973', '0.48869', '0.064852', '-0.19179', '0.65216', '0.32733', '-0.29252', '-0.41058', '-0.95215', '0.002077', '0.43666', '0.088961', '-0.070568', '0.20559', '-0.54051', '-0.87095', '-0.054644', '-0.091465', '0.1407', '0.30034', '0.78894', '-0.039658', '0.077871', '0.32157', '0.63414', '-0.49386', '0.59048', '-0.29637', '-0.080738', '-0.13208', '-0.32004', '0.13991', '-0.53616', '-0.44044', '-0.11007', '-0.36957', '0.34056', '-0.0026693', '0.13948', '-0.24647', '0.12496', '0.24686', '-0.27538', '-1.0699', '0.038913', '0.22792', '0.10552', '-0.17199', '-0.93949', '0.22155', '-0.55033', '0.51691', '0.14497', '-0.37452', '0.74865', '-0.48413', '-0.65177', '-0.46451', '0.047322', '-0.46728', '0.22168', '-0.26429', '0.17448', '0.12428', '0.24448', '-0.35366', '0.81222', '-0.091716', '-0.044557', '0.51706', '0.0083291', '0.039256', '-0.46194', '0.15737', '0.21966', '-0.068805', '-0.11275', '0.089789', '0.084077', '0.22614', '-0.033367', '-0.37446', '0.26734', '-0.082283', '-0.36108', '0.32939', '0.74576', '-0.058493', '0.29798', '0.22355', '-0.36508', '-0.46061', '-0.41051', '0.44275', '-0.20983', '0.42571', '0.52918', '0.10028', '-0.33121', '-0.070477', '0.095435', '0.46067', '0.50688', '1.1697', '-0.033038', '0.54687', '0.12004', '0.15455', '-0.47783', '0.24525', '0.13621', '-0.035706', '0.73538', '-0.075418', '-0.94182', '-0.10082', '0.25153', '-0.57397', '0.9554', '0.52676', '0.32783', '-0.087804', '-0.17399', '-0.1534', '-0.39397', '0.042245', '0.10198', '-0.25497', '0.21075', '-0.46222', '-0.01793', '0.058087', '-0.0063209', '-0.35869', '-0.76988', '-0.72588', '0.25856', '0.24766', '-0.3618', '-0.17659', '0.23047', '0.15079', '-0.37018', '0.1222', '-0.52281', '0.22416', '-0.25709', '-0.20888', '-0.56476', '-0.38673', '-0.35598', '-0.31188', '-0.20427', '1.4803', '-0.84484', '-0.40866', '-0.14147', '0.54467', '0.22222', '0.38865', '0.39405', '0.15172', '-0.53594', '0.73612', '0.17512', '-0.081019', '-0.34846']\n",
      "['ውዕል', 'ተጠቃምነት', '-0.05704', '0.04993', '-0.40998', '-0.40681', '-0.40841', '-0.36614', '0.39064', '-0.13149', '0.45325', '-0.17003', '-0.15589', '-0.047645', '0.10144', '-0.43402', '-0.073125', '-0.29392', '0.24158', '-0.21696', '0.11403', '0.1997', '0.55818', '-0.29538', '0.47069', '-0.075496', '0.274', '-0.19189', '0.0010476', '-0.26936', '-0.21977', '-0.3441', '0.080021', '0.57378', '-0.37324', '0.36645', '-0.47413', '0.0083299', '-0.36324', '0.18242', '0.47708', '-0.047404', '0.61104', '-0.52493', '0.29623', '-0.048455', '0.079936', '0.25027', '-0.3267', '-0.43373', '-0.3067', '-0.65653', '-0.16797', '0.10492', '-0.46873', '0.40269', '0.27184', '-0.2211', '0.66769', '0.78311', '0.44318', '0.083334', '0.31701', '-0.037783', '-0.27908', '0.22544', '0.3737', '-0.13262', '-0.045271', '0.32806', '0.33561', '0.68947', '-0.13045', '0.014803', '0.67766', '0.42057', '-0.31121', '-0.23576', '0.053972', '-0.11864', '-0.40582', '0.68996', '-0.11565', '-0.26702', '-0.16941', '-0.62539', '-0.088667', '0.07768', '-0.34695', '0.3547', '0.2206', '-0.17335', '-0.11446', '0.13341', '-0.19268', '-0.30656', '0.24858', '-0.30086', '-0.13404', '-0.4234', '0.17584', '-0.59491', '0.35166', '-0.33006', '0.52406', '0.24221', '0.64997', '0.15736', '-0.10331', '-0.2661', '0.052428', '-0.25476', '0.80988', '0.2092', '-0.36593', '0.26679', '0.18602', '-0.11601', '0.30197', '-0.43469', '0.005644', '-0.27612', '-0.050153', '-0.065141', '-0.17278', '-0.08445', '-0.40777', '-0.20038', '-0.17535', '0.7208', '0.23351', '0.58742', '0.31378', '1.0683', '-0.59802', '-0.088521', '0.13551', '0.12412', '0.28003', '-0.25427', '-0.12718', '-0.15379', '0.10268', '0.40896', '0.41452', '0.036385', '0.14575', '0.38609', '0.4171', '0.21898', '0.1076', '0.064412', '-0.49077', '-0.45724', '-0.32876', '0.15408', '0.42135', '-0.23353', '0.58639', '-0.36061', '0.025024', '0.21517', '0.17754', '-0.050524', '0.11844', '-0.53986', '0.58504', '-0.031249', '0.23548', '0.31993', '0.0053709', '0.26776', '0.010774', '0.074104', '0.11649', '-0.23027', '-0.31922', '0.02676', '-0.083956', '-0.31326', '-0.56149', '-0.48738', '0.0042678', '0.96746', '0.21136', '-0.4978', '0.0068606', '-0.043961', '-0.44407', '-0.60889', '0.067149', '0.23823', '0.4325', '0.27395', '-0.53506', '0.41733', '0.71381', '-0.069653', '-0.0023053', '-0.075056', '0.085712', '-0.52642', '0.064848', '-0.15104', '0.48522', '-0.3549', '0.36183', '0.10792', '0.086656', '0.27414', '0.32942', '0.10356', '0.016314', '0.434', '0.33877', '0.05328', '-0.18411', '0.19106', '0.28586', '0.17522', '-0.59382', '0.26406', '-0.49267', '0.55208', '0.48232', '-0.018742', '0.31576', '0.10505', '-0.42304', '0.02073', '-0.13951', '-0.18574', '0.38901', '-0.43224', '0.46061', '0.083746', '-0.27847', '-0.26335', '-0.54671', '-0.20637', '-0.10666', '0.42948', '0.099987', '-0.19328', '-0.62265', '0.2268', '0.13627', '-0.20575', '-0.22603', '0.41308', '-0.083077', '0.513', '0.41485', '0.020573', '0.042199', '-0.22012', '0.13902', '-0.43413', '-0.22692', '-0.35427', '-0.5115', '-0.19409', '0.38688', '-0.27986', '0.45191', '0.36651', '-0.24556', '-0.10685', '-0.35487', '0.1092', '-0.21731', '-0.041473', '0.16205', '-0.10402', '0.69406', '-0.049031', '-0.53447', '-0.11286', '-0.13263', '-0.082076', '-0.14199', '0.26898', '0.31906', '0.5145', '0.11851', '0.14969', '0.064208', '-0.4003', '-0.18379', '0.61269', '0.3849', '-0.06351', '0.60075', '-0.27968', '-0.4897', '-0.92812', '-0.20232', '-0.12723', '0.53649', '0.22889', '-0.1422', '0.20306', '-0.001207', '0.14801', '0.67473', '0.80239', '0.22994', '0.65039', '-0.60906', '0.037774', '-0.02812', '0.14037', '0.052809', '-0.49969', '-0.40681', '0.14211', '0.41698', '-0.60145', '0.46993', '-0.22061', '0.015141', '-0.063485', '-0.27607', '0.11843', '0.39372', '-0.00092119', '-0.072068', '0.10976', '-0.48502', '0.10557', '-0.21367', '-0.63814', '-0.074262', '0.024324', '0.088602', '0.19829', '0.12186', '0.022732', '-0.62694', '-0.09893', '0.41863', '0.11942', '0.32397', '-0.10515', '0.072014', '0.091227', '-0.15895', '0.039411', '-0.30129', '0.44142', '0.24197', '0.41603', '-0.017185', '-0.41094', '-0.046335', '-0.23846', '-0.38177', '0.63533', '-0.19031', '0.58904', '0.13891', '-0.13771', '-0.81868', '0.40774', '0.11518', '-0.1946', '-0.50787', '-0.19783', '-0.0066443', '-0.1118', '-0.18876', '0.11043', '-0.25403', '-0.31297', '0.8893', '-0.078096', '0.071323', '-0.0066896', '0.49074', '-0.35227', '0.22254', '0.672', '0.12136', '-0.21965', '-0.39768', '0.29356', '0.28872', '-0.063581', '0.78174', '-0.016983', '-0.5568', '0.25194', '-0.30347', '0.021072', '-0.089732', '-0.015928', '-0.438', '-0.20495', '-0.30526', '0.12393', '0.1756', '0.11661', '-0.26437', '0.3879', '-0.56157', '0.21432', '-0.015015', '0.18088', '-0.40205', '-0.36192', '-0.055951', '0.3549', '0.21709', '-0.052599', '0.27578', '0.022275', '0.3991', '0.064205', '-0.30918', '-0.2543', '0.094513', '-0.10931', '0.15593', '0.43633', '0.53209', '-0.4366', '0.031814', '-0.21419', '0.15176', '0.012177', '-0.096612', '-0.39091', '0.19131', '-0.19803', '-0.29116', '-0.68175', '0.07026', '0.33928', '-0.5249', '-0.58691', '0.069713', '0.16977', '-0.15885', '0.23701', '0.29539', '-0.079462', '-0.26504', '0.4454', '0.41136', '-0.028037', '-0.17922', '-0.093268', '-0.16232', '-0.20663', '0.90068', '-0.057661', '0.14445', '0.3609', '-0.39608', '0.48018', '-0.14722', '0.31754', '-0.036044', '-0.085558', '0.085036', '-0.023716', '0.11792', '0.13122', '-0.24634', '-0.47369', '0.10425', '-0.095802', '-0.43891', '0.624', '-0.39378', '0.28636', '0.48585', '0.4441', '-0.94332', '0.016229', '0.15515', '-0.69572', '-0.4065', '-0.10186', '0.5752', '0.1327', '-0.20025', '0.19206', '-0.36245', '-0.83958', '-0.045918', '-0.62869', '0.11907', '0.58515', '0.2423', '-0.11512', '0.22855', '0.24053', '-0.11232', '-0.88377', '0.35387', '-0.44017', '0.7414', '-0.064522', '-0.63737', '0.68717', '0.39045', '-0.27889', '0.39861', '-0.086706', '-0.21989', '-0.019484', '0.16232', '-0.37724']\n",
      "['ይሙት”', 'ኢሉ', '0.12723', '0.24511', '-0.16781', '0.079863', '0.017739', '-0.41044', '0.15048', '-0.30641', '0.046508', '0.08359', '0.25539', '-0.065489', '-0.029054', '-0.14599', '0.03582', '-0.31864', '0.40304', '-0.01836', '-0.088909', '-0.053678', '0.13169', '0.052744', '0.37612', '0.11495', '-0.024743', '-0.028617', '-0.27758', '-0.12096', '0.08537', '-0.065905', '0.36706', '0.39599', '-0.00083678', '0.048039', '0.087016', '0.32368', '-0.27581', '0.016857', '0.11035', '-0.1731', '0.19355', '0.35199', '0.1229', '0.19275', '-0.051474', '0.14103', '-0.18487', '-0.059122', '-0.080096', '-0.4082', '0.03199', '0.58144', '-0.28847', '0.045095', '0.64507', '-0.29421', '0.19493', '0.14088', '0.39044', '0.10499', '0.20265', '0.13569', '-0.44852', '0.24826', '0.02705', '-0.079456', '0.14463', '0.0057754', '-0.37589', '0.2558', '0.062408', '0.14626', '0.55403', '0.72775', '-0.017961', '0.053359', '0.22095', '-0.21914', '0.18387', '0.15174', '0.28634', '0.051918', '-0.10842', '0.1222', '0.12603', '0.2492', '0.14501', '0.038491', '-0.16315', '-0.071018', '-0.26965', '0.12536', '-0.25859', '0.23121', '0.2802', '-0.19694', '-0.1273', '-0.44162', '-0.2584', '-0.24906', '-0.17339', '-0.40287', '0.33113', '0.32862', '0.11491', '-0.30929', '-0.17091', '0.32801', '-0.12841', '0.03725', '0.01749', '-0.12277', '-0.22411', '0.16585', '-0.14516', '-0.12345', '0.30939', '-0.15172', '0.21744', '-0.20456', '0.28864', '0.16686', '0.051994', '-0.064629', '-0.13972', '-0.35282', '0.035152', '-0.20654', '0.4087', '0.24814', '0.2833', '0.5249', '-0.16706', '0.30793', '-0.19857', '-0.054355', '0.071824', '0.040123', '0.15532', '0.10342', '0.047037', '0.22622', '0.065203', '0.19964', '0.33836', '-0.011057', '-0.36897', '0.43949', '-0.13908', '0.19575', '-0.20271', '-0.42079', '-0.021542', '0.14854', '0.32653', '-0.39761', '-0.10589', '-0.38952', '-0.098116', '0.3922', '0.12664', '0.43536', '0.081844', '-0.53896', '0.13019', '0.20123', '0.05696', '0.1104', '0.062233', '0.11875', '-0.14034', '-0.47114', '-0.25918', '0.17228', '-0.21537', '-0.30101', '0.057856', '-0.1886', '0.1895', '-0.039707', '0.088341', '0.50999', '0.058505', '-0.41438', '0.078863', '0.060691', '0.19108', '-0.02827', '0.15213', '0.2738', '0.25384', '0.00045393', '-0.17667', '0.27108', '0.22007', '0.13418', '0.34516', '-0.21878', '0.13734', '-0.26447', '0.024577', '-0.27664', '0.18514', '-0.31957', '-0.16465', '0.087325', '-0.19194', '0.25793', '0.053888', '0.11451', '0.15269', '0.0013604', '0.10463', '-0.26722', '0.20718', '-0.080892', '0.19912', '0.095465', '-0.049673', '0.50787', '-0.31307', '0.68402', '-0.014701', '-0.23334', '0.15661', '0.18115', '-0.19644', '0.25847', '-0.10342', '-0.17284', '-0.26949', '-0.092103', '0.21218', '0.085364', '-0.18633', '0.17038', '0.042693', '-0.33014', '0.19377', '-0.036346', '-0.22911', '-0.3', '-0.39367', '0.38052', '0.13022', '0.044509', '-0.040192', '0.23209', '0.28274', '0.70406', '0.16807', '-0.061307', '-0.086622', '-0.23255', '0.17183', '-0.2581', '-0.024074', '-0.34086', '-0.32093', '0.11134', '0.17999', '0.1159', '0.24666', '-0.22909', '-0.12381', '-0.30306', '0.10106', '-0.16098', '0.029922', '-0.034446', '-0.035653', '-0.030697', '0.26179', '0.034895', '0.016452', '-0.13479', '0.035347', '0.025407', '-0.20856', '0.1873', '0.082739', '0.20866', '-0.21998', '0.11402', '0.082624', '0.02315', '-0.19091', '0.016517', '0.35457', '-0.019037', '0.19786', '-0.29412', '-0.38387', '-0.3761', '-0.18014', '0.081699', '0.014577', '0.066584', '0.054168', '0.0096903', '-0.18405', '0.12949', '0.34597', '-0.12535', '-0.19146', '0.44051', '0.044899', '-0.37639', '-0.15459', '0.0063926', '0.077694', '-0.061197', '0.039688', '0.073623', '-0.40885', '-0.28096', '0.1353', '-0.43137', '0.068535', '0.17633', '0.0010596', '0.30391', '0.47347', '-0.1319', '-0.42893', '-0.20795', '-0.044215', '0.35681', '-0.28076', '-0.31282', '0.18781', '-0.10478', '-0.32168', '0.25199', '-0.071755', '0.1843', '0.00082669', '0.27764', '-0.050206', '0.011218', '0.30615', '0.036386', '0.25496', '-0.30503', '-0.048862', '0.3227', '-0.15508', '0.37864', '0.23528', '0.57495', '0.13784', '-0.3464', '-0.033718', '-0.060605', '-0.10081', '0.042495', '0.12263', '0.20964', '-0.13675', '-0.55742', '-0.10751', '-0.088484', '0.19609', '0.21518', '-0.24229', '0.019946', '-0.0057588', '0.44795', '0.10443', '0.1583', '-0.0064599', '0.019384', '0.35011', '-0.19349', '0.019816', '-0.17194', '0.043853', '-0.19103', '-0.28522', '-0.0050761', '0.18114', '-0.097397', '0.029958', '-0.22857', '0.30549', '-0.24884', '0.38892', '-0.43097', '-0.19032', '0.046716', '-0.17931', '0.14114', '-0.070533', '-0.0046743', '-0.081543', '-0.057431', '0.052209', '0.25556', '0.18113', '0.10589', '0.11197', '0.09933', '-0.36322', '0.050409', '-0.097732', '0.035552', '-0.1876', '-0.070195', '-0.37007', '0.14979', '0.066201', '0.19025', '0.028262', '-0.052811', '0.026339', '-0.068986', '-0.18283', '-0.24466', '-0.14762', '0.18568', '0.62805', '-0.6433', '-0.090571', '0.019728', '0.33789', '0.13459', '0.13331', '-0.21388', '0.23527', '-0.34079', '-0.22862', '-0.30611', '0.4414', '-0.2451', '0.13329', '-0.34857', '-0.47552', '-0.15837', '0.25382', '0.24482', '0.1462', '-0.1171', '0.26003', '0.010501', '-0.05838', '0.26785', '0.099135', '-0.040887', '0.20465', '0.22833', '-0.14428', '-0.45002', '0.39942', '-0.24985', '-0.026379', '0.21503', '0.02337', '0.16184', '0.05505', '-0.044097', '0.07455', '0.034065', '-0.00035545', '0.23271', '0.030432', '0.16827', '-0.42876', '0.18979', '-0.01966', '0.14801', '0.27023', '0.14186', '-0.40773', '0.27358', '-0.11691', '0.28811', '-0.027236', '0.18545', '-0.073165', '-0.39219', '-0.19219', '-0.093402', '0.34727', '-0.0063809', '-0.06421', '0.053608', '-0.4497', '-0.36471', '-0.11986', '0.095913', '-0.033322', '0.1931', '-0.38244', '-0.014266', '0.30736', '0.054246', '-0.21447', '-0.13019', '-0.12231', '-0.11146', '0.22344', '0.029002', '-0.19043', '-0.17454', '-0.066542', '0.19767', '0.18447', '-0.033308', '-0.23149', '0.16043', '-0.11143', '0.16897']\n",
      "['-0.018209', '0.029812', '-0.0356', '0.074346', '-0.040812', '-0.13646', '-0.050324', '-0.25912', '-0.28196', '0.478', '0.0046443', '-0.0087728', '0.3114', '0.051673', '-0.10134', '0.085107', '0.60813', '-0.29625', '-0.35525', '-0.12793', '-0.32574', '-0.12095', '0.10874', '-0.10687', '0.091166', '0.18049', '0.26284', '0.028173', '0.43744', '-0.053909', '0.23135', '0.050794', '-0.012359', '-0.5629', '0.1999', '0.13762', '-0.2159', '0.13175', '-0.0081484', '-0.28136', '-0.30449', '-0.18941', '0.024902', '0.081283', '-0.27732', '0.42548', '-0.006173', '0.12335', '-0.25522', '-0.13991', '-0.12348', '0.03495', '0.45686', '0.12487', '-0.15988', '-0.026406', '0.33302', '-0.084368', '0.23451', '-0.099425', '-0.17012', '0.12102', '-0.15533', '0.088441', '0.0092296', '0.18796', '-0.024653', '-0.25024', '0.10589', '0.4427', '-0.063659', '-0.23896', '-0.099882', '0.0021527', '-0.015522', '-0.19102', '0.048779', '-0.40357', '-0.07498', '-0.035358', '-0.086549', '0.35758', '0.083591', '0.129', '0.03045', '0.056215', '-0.19296', '0.073853', '0.21657', '-0.1904', '-0.20921', '-0.099611', '0.18543', '-0.11374', '0.19485', '0.10624', '0.27364', '-0.041279', '0.16211', '0.12724', '0.045273', '-0.018676', '0.035286', '-0.1299', '0.061448', '0.41474', '-0.033707', '0.13586', '-0.097552', '0.045317', '0.19936', '-0.17152', '-0.071932', '-0.37703', '0.16142', '0.25837', '0.2714', '-0.13394', '0.19824', '-0.59373', '-0.26914', '-0.20713', '0.26089', '-0.12338', '-0.19476', '-0.17354', '0.18126', '-0.40798', '0.25666', '0.33206', '0.028562', '0.3273', '-0.077223', '-0.056571', '0.45657', '0.021385', '0.0054356', '-0.41445', '-0.13268', '0.22459', '0.1732', '0.05721', '0.20693', '0.2235', '-0.029656', '0.050174', '0.076354', '-0.22177', '0.36353', '-0.084222', '-0.15127', '-0.21252', '0.078727', '-0.50671', '-0.061193', '0.18167', '0.19528', '0.31848', '-0.035934', '0.11423', '0.0058181', '-0.090224', '-0.21008', '0.048252', '-0.03661', '-0.17715', '-0.14856', '0.21455', '0.21496', '0.18635', '-0.005101', '-0.49651', '-0.010272', '-0.04101', '-0.10265', '0.010259', '0.0076379', '-0.42074', '0.36165', '-0.074414', '-0.21731', '0.17294', '-0.13161', '-0.59986', '-0.075141', '-0.023196', '-0.0081985', '0.30905', '-0.4343', '0.13846', '0.37644', '0.15187', '-0.32958', '0.28533', '0.15805', '-0.10575', '-0.13304', '0.12123', '0.25184', '-0.15561', '-0.11739', '-0.21028', '0.19617', '-0.0046061', '-0.014479', '0.025554', '-0.022651', '-0.029137', '-0.2108', '-0.053408', '0.20343', '0.019017', '-0.06793', '0.14174', '-0.22062', '0.1248', '-0.031019', '0.21031', '0.18074', '0.11877', '-0.17178', '-0.026528', '-0.093573', '-0.25889', '-0.14746', '0.0076391', '-0.034328', '-0.078581', '0.15514', '-0.28111', '0.14578', '0.17592', '0.22927', '0.0015552', '-0.12281', '-0.1151', '-0.15202', '-0.22968', '0.051864', '0.22361', '0.29733', '0.11422', '-0.17446', '0.13664', '-0.090038', '0.18567', '0.1994', '0.15928', '0.048057', '0.2895', '0.2037', '0.083405', '-0.062085', '-0.22546', '-0.11717', '0.013911', '0.057741', '-0.28998', '-0.04396', '-0.21272', '-0.049131', '-0.056012', '-0.0043545', '-0.099373', '-0.36745', '-0.14393', '0.12867', '-0.4007', '-0.45421', '0.39497', '0.03716', '0.10307', '-0.089553', '-0.057571', '-0.13411', '0.18572', '0.29397', '0.033628', '-0.14355', '0.10771', '0.18571', '-0.11703', '0.39292', '-0.078285', '-0.26106', '-0.063817', '-0.15223', '-0.014482', '0.10403', '0.39242', '0.10405', '-0.03489', '0.11781', '0.18235', '-0.044506', '-0.38513', '-0.30769', '0.024865', '-0.22017', '0.016505', '0.0014764', '-0.096886', '0.20501', '-0.14586', '0.37048', '0.094123', '-0.00032706', '0.13935', '-0.029836', '0.24237', '0.14395', '0.04367', '-0.087375', '0.076935', '0.25199', '0.053642', '-0.23908', '0.20718', '0.24832', '-0.083051', '-0.086605', '-0.081688', '-0.15407', '0.052346', '0.00095417', '-0.057291', '0.062643', '-0.13846', '0.18894', '-0.05429', '0.10643', '-0.11829', '0.25112', '-0.031087', '-0.27516', '0.42308', '-0.12125', '0.10886', '0.35518', '-0.16671', '0.21971', '0.14164', '-0.18253', '-0.020625', '-0.288', '0.11329', '-0.19837', '0.049329', '-0.14259', '0.31122', '0.3277', '-0.31243', '-0.10183', '-0.24155', '0.073826', '-0.26486', '0.17138', '-0.22271', '0.16986', '-0.18281', '-0.49686', '-0.20505', '-0.13852', '0.082334', '-0.24617', '-0.10756', '0.086351', '0.049009', '-0.090652', '0.20625', '-0.0095068', '-0.24019', '0.1357', '-0.056916', '0.40234', '-0.02922', '0.50792', '-0.05769', '0.17711', '0.21378', '-0.024463', '-0.0052455', '0.26774', '0.056786', '0.082621', '-0.14602', '0.027746', '-0.50281', '-0.091431', '0.0056489', '-0.22463', '-0.00066117', '0.0010722', '-0.56189', '0.095044', '-0.11298', '0.089465', '0.12521', '-0.027773', '0.16147', '-0.26939', '-0.078812', '-0.33943', '-0.055525', '-0.1578', '0.36259', '-0.36874', '0.10161', '0.2317', '0.074662', '0.12398', '0.22144', '0.15121', '0.24969', '-0.11798', '-0.34754', '0.072955', '-0.17207', '-0.075596', '-0.28805', '0.16157', '-0.20873', '0.42142', '0.10585', '-0.28767', '-0.24075', '-0.27006', '0.21859', '-0.035333', '-0.099347', '-0.13582', '-0.23707', '-0.073151', '0.16804', '0.052383', '0.0087524', '-0.15797', '-0.097885', '0.23751', '-0.30939', '0.16458', '-0.10529', '-0.066716', '-0.45519', '0.082985', '0.18588', '0.18631', '0.16951', '0.21693', '0.41372', '-0.39727', '-0.3859', '-0.11491', '-0.34289', '0.033104', '0.24923', '-0.41361', '-0.008626', '-0.17295', '-0.1111', '-0.16415', '0.063163', '-0.12115', '0.27748', '0.13097', '-0.18739', '-0.46938', '-0.44678', '-0.14458', '-0.001122', '-0.02326', '0.12825', '-0.054849', '0.031118', '0.013132', '0.11577', '0.18162', '0.032802', '-0.05912', '0.14392', '-0.1649', '-0.38976', '-0.085353', '-0.2102', '-0.2907', '-0.22274', '-0.027399', '0.052882', '0.092646', '-0.13125', '0.31734', '-0.058723', '0.082676', '-0.11315', '-0.25533', '0.024216', '-0.31848', '-0.14614', '0.42578', '0.2956', '0.13162', '-0.25568', '0.005223', '0.10085', '0.11281', '0.034552', '0.0055542', '-0.25413', '0.41016', '0.19326', '-0.2343', '-0.26897']\n",
      "['35.6', 'ሚልዮን', '0.057437', '-0.056217', '-0.26061', '0.13915', '0.038091', '-0.062936', '0.27849', '-0.18674', '0.032403', '-0.17654', '-0.10552', '-0.033889', '-0.12552', '-0.093654', '0.010716', '0.070797', '0.091977', '0.39913', '-0.20009', '-0.14564', '0.35373', '-0.20963', '0.33003', '-0.16232', '-0.12466', '-0.19459', '0.057541', '0.13777', '-0.14434', '0.030589', '0.20191', '0.26349', '-0.12436', '-0.087867', '0.052197', '0.01054', '-0.50003', '0.24302', '-0.33649', '-0.091213', '0.27689', '-0.041438', '0.044391', '0.19455', '-0.16183', '0.31879', '-0.10238', '-0.12909', '0.11534', '-0.23086', '-0.03828', '0.22173', '-0.23773', '-0.29269', '0.20294', '-0.22555', '0.38184', '0.1134', '0.091799', '-0.18802', '0.024002', '0.14979', '-0.034223', '-0.044019', '0.0084814', '0.15999', '0.32021', '-0.066407', '-0.16885', '0.17896', '-0.12457', '0.17835', '0.15083', '0.41388', '-0.1675', '0.26861', '-0.053018', '-0.097612', '0.038618', '0.31604', '0.2222', '-0.039637', '-0.28356', '0.14194', '-0.039273', '0.35786', '0.11164', '-0.12547', '0.091178', '0.27516', '-0.34452', '-0.085412', '-0.3192', '-0.11085', '-0.10344', '0.24967', '-0.052761', '-0.14173', '-0.19338', '-0.022205', '-0.029624', '-0.11732', '0.26205', '0.082079', '0.49133', '-0.091761', '-0.38008', '-0.0836', '0.081939', '0.11594', '-0.10771', '0.036948', '-0.32098', '-0.16456', '-0.0099525', '0.24848', '0.33415', '0.010636', '0.10824', '-0.38665', '-0.093282', '-0.16435', '0.23385', '-0.34499', '-0.22956', '-0.59577', '-0.13289', '0.040196', '-0.13219', '0.41571', '0.1786', '0.3127', '-0.2449', '0.0020971', '-0.29201', '-0.21906', '-0.13536', '-0.014491', '0.06796', '0.078937', '0.10543', '0.038338', '-0.040595', '0.14773', '0.043335', '0.11475', '-0.31767', '0.19316', '0.077575', '0.18536', '-0.45593', '-0.14751', '0.13072', '-0.038491', '0.11886', '-0.18818', '-0.0090187', '-0.17804', '-6.0035e-05', '0.42317', '0.13882', '0.25022', '0.0028738', '-0.29647', '0.19925', '-0.14104', '-0.25153', '0.17801', '0.078775', '0.089124', '0.20086', '-0.22029', '0.14768', '0.095217', '-0.18819', '-0.027275', '-0.15915', '-0.068671', '0.12647', '0.019838', '-0.18554', '0.60931', '0.14037', '-0.41594', '-0.10496', '-0.036479', '-0.11542', '0.0643', '0.094566', '0.14088', '0.060066', '-0.069405', '-0.36956', '0.18737', '0.25846', '-0.030988', '0.16368', '-0.11824', '0.14733', '-0.36159', '-0.30244', '-0.22481', '0.17495', '-0.19005', '0.1871', '0.18999', '-0.10157', '0.38785', '0.0012761', '-0.14122', '0.18885', '-0.021672', '0.16046', '-0.18078', '0.22181', '0.10787', '0.33355', '0.044982', '-0.096832', '0.28773', '-0.15411', '0.43607', '0.045261', '-0.372', '-0.15633', '0.19842', '0.043658', '0.15587', '0.12545', '-0.26895', '0.062717', '-0.080934', '-0.0069756', '0.33353', '-0.12571', '0.12141', '-0.24885', '-0.34018', '0.25963', '-0.011971', '0.12955', '-0.18048', '-0.29959', '0.086444', '0.30895', '-0.27144', '-0.25003', '0.10502', '-0.037334', '0.1183', '0.077663', '0.025017', '-0.17893', '-0.064419', '0.040152', '-0.50899', '-0.12138', '-0.37414', '-0.31535', '0.2146', '0.13539', '-0.12516', '0.15845', '-0.050018', '0.046361', '0.078704', '0.25897', '-0.32659', '-0.087192', '0.092425', '-0.039214', '0.1328', '0.25783', '0.0059063', '-0.0058542', '-0.13071', '-0.3594', '-0.11539', '-0.054056', '0.12871', '-0.19003', '0.42474', '-0.24069', '0.16156', '-0.44934', '0.078835', '-0.021955', '0.0014625', '0.14534', '0.029626', '0.12035', '-0.47464', '-0.46761', '-0.17465', '-0.40669', '-0.22113', '0.19127', '0.040911', '0.18442', '-0.09722', '-0.077027', '-0.2232', '0.2746', '0.10278', '0.07329', '0.28035', '0.090312', '-0.43612', '-0.29976', '0.16987', '0.073752', '0.036908', '-0.23486', '-0.061636', '-0.26713', '-0.30268', '-0.011358', '-0.19531', '0.33239', '-0.12322', '-0.15009', '-0.12083', '0.10745', '0.14326', '-0.33721', '-0.34546', '-0.013855', '0.24491', '-0.14483', '-0.3202', '-0.10463', '-0.29633', '-0.13569', '-0.18785', '0.079691', '-0.15294', '0.098372', '0.032386', '0.084181', '0.13472', '0.006111', '0.19812', '0.076979', '-0.23724', '-0.023818', '0.24645', '0.089878', '0.10477', '0.2564', '0.34791', '0.26011', '-0.43128', '-0.011386', '-0.070473', '-0.1708', '0.074973', '0.079452', '0.10258', '-0.017221', '-0.29035', '-0.034735', '0.23635', '0.066368', '0.18665', '-0.32784', '0.19086', '0.057516', '0.28588', '-0.0221', '-0.014833', '0.12234', '-0.23019', '0.22134', '-0.042384', '-0.13822', '0.017275', '0.20194', '-0.56398', '0.10319', '0.27102', '0.071642', '-0.34869', '-0.042711', '-0.09204', '-0.037479', '0.031192', '0.24413', '0.13158', '0.092488', '-0.073257', '0.028543', '0.092286', '0.090824', '0.19906', '-0.17482', '-0.28938', '0.24808', '0.33528', '-0.04474', '0.15943', '0.010811', '0.13416', '-0.065427', '0.11665', '-0.13541', '0.26126', '-0.24187', '-0.10033', '-0.0053912', '0.29338', '-0.10145', '0.23734', '-0.03066', '0.1559', '-0.069681', '-0.055133', '-0.15514', '-0.29781', '-0.058764', '0.11931', '0.45011', '0.10328', '-0.021881', '-0.35391', '0.090652', '-0.22318', '0.1529', '-0.36751', '-0.012248', '-0.29881', '-0.12364', '-0.19348', '0.1983', '-0.02134', '0.0083274', '-0.072212', '-0.17786', '-0.075281', '0.047176', '0.28022', '-0.063141', '-0.11654', '0.038558', '-0.11797', '-0.38758', '0.29169', '-0.0076734', '-0.038813', '-0.20469', '0.1896', '-0.29193', '-0.0080607', '0.1595', '-0.14094', '-0.1808', '0.51639', '-0.078022', '0.24172', '0.0039889', '0.0010445', '-0.084481', '0.072358', '-0.022116', '0.18443', '-0.12727', '-0.19782', '-0.15603', '0.28846', '0.1472', '-0.15525', '0.041635', '0.016495', '-0.10803', '0.011151', '-0.0022332', '0.2616', '-0.18142', '0.010582', '0.018607', '-0.21949', '-0.50156', '-0.1091', '0.13819', '0.020905', '-0.13706', '0.10495', '-0.3904', '-0.42856', '-0.2584', '-0.14711', '0.11539', '0.18451', '-0.14159', '0.22422', '0.26798', '-0.023027', '-0.3049', '-0.15808', '0.022199', '-0.39621', '0.10365', '-0.055584', '0.03595', '-0.053022', '-0.22237', '-0.10364', '-0.052345', '-0.22224', '-0.4336', '0.29494', '0.035255', '-0.15365']\n",
      "['ዝውዕል', 'ሓገዝ', '0.17514', '0.0082383', '-0.45892', '0.059731', '-0.16342', '-0.26118', '0.1156', '-0.19892', '0.041867', '-0.19077', '-0.24199', '-0.071464', '0.071382', '-0.2222', '-0.17777', '-0.1974', '0.3919', '0.23043', '-0.17058', '-0.11374', '0.4269', '-0.089194', '0.20271', '-0.03463', '-0.002082', '-0.14428', '-0.028079', '0.34391', '-0.42085', '-0.075853', '0.20423', '0.53469', '-0.25284', '0.094064', '-0.25296', '0.076779', '-0.22755', '0.022611', '-0.088211', '-0.17238', '0.21265', '-0.17931', '0.023265', '-0.040748', '-0.099196', '0.31842', '-0.20731', '-0.095104', '0.21809', '-0.42902', '0.046116', '0.28975', '-0.25598', '-0.34035', '0.030543', '-0.34661', '0.39198', '0.013738', '-0.092304', '-0.03922', '0.15671', '-0.17624', '-0.030218', '0.023567', '-0.0034253', '0.33068', '0.12043', '-0.14203', '-0.018376', '0.2068', '-0.18532', '0.13579', '0.12167', '0.51721', '-0.10035', '0.10417', '0.034957', '-0.16716', '0.088355', '0.32133', '0.071337', '0.099252', '-0.3274', '0.0051079', '-0.01956', '0.19896', '-0.045906', '0.03857', '0.34584', '0.26517', '-0.21328', '0.030837', '-0.34927', '-0.28956', '-0.058252', '0.050168', '0.17392', '-0.086038', '-0.26589', '-0.3417', '0.28357', '0.1506', '0.25874', '0.16021', '0.46542', '-0.034108', '-0.40631', '-0.11104', '0.11078', '0.12639', '-0.0083667', '0.044059', '-0.40668', '-0.073549', '0.27012', '0.091968', '0.27637', '-0.061549', '0.12165', '-0.34281', '-0.073257', '-0.015124', '0.14412', '-0.42948', '-0.2451', '-0.39517', '0.0059208', '0.019271', '-0.032069', '0.25987', '0.31508', '0.63541', '-0.25276', '0.18556', '-0.092663', '-0.35646', '-0.093044', '0.042675', '0.23944', '-0.009866', '-0.04737', '0.36192', '0.075028', '0.23253', '0.038765', '0.31984', '-0.094753', '0.14077', '-0.10177', '0.2762', '-0.2081', '-0.42222', '0.22575', '0.2454', '0.24851', '-0.071724', '0.11983', '-0.27788', '-0.15978', '0.441', '0.12991', '-0.04956', '0.025497', '-0.52429', '0.26467', '-0.076551', '-0.0010316', '0.24687', '-0.076074', '0.15058', '0.098029', '-0.26293', '0.31627', '-0.1847', '-0.11346', '-0.11777', '-0.088706', '-0.15134', '-0.13859', '0.094572', '-0.20462', '0.65771', '0.1256', '-0.39889', '-0.16725', '0.017563', '-0.26381', '0.12195', '-0.015829', '0.13198', '0.12452', '-0.074625', '-0.27705', '0.20935', '0.17681', '0.0035356', '0.17439', '-0.27585', '0.062993', '-0.23063', '-0.1086', '-0.18699', '0.21768', '-0.46399', '0.15947', '0.1868', '0.0070392', '0.4799', '0.13972', '0.079837', '0.14176', '-0.029908', '0.26609', '-0.16058', '0.33801', '-0.21785', '0.33', '-0.15349', '-0.22106', '0.34426', '-0.17272', '0.29508', '0.18115', '-0.3542', '0.0033037', '0.18301', '-0.20139', '0.16429', '0.04055', '-0.19205', '-0.086775', '0.015082', '-0.080258', '0.49048', '-0.21128', '0.058621', '-0.20065', '-0.066428', '-0.060817', '0.17583', '0.17761', '0.046127', '-0.21175', '0.00047715', '0.38513', '-0.041359', '-0.38694', '0.2256', '-0.15435', '0.49816', '0.27955', '0.065837', '-0.20324', '0.077', '-0.093942', '-0.57317', '-0.18292', '-0.51649', '-0.1887', '-0.010441', '0.21831', '-0.10991', '0.17209', '0.041271', '-0.0052544', '0.082229', '0.10337', '-0.098565', '-0.05651', '0.089582', '-0.1239', '0.11174', '0.32359', '0.042475', '0.062108', '-0.092815', '-0.27548', '0.14518', '-0.12481', '0.16116', '-3.9997e-05', '0.40395', '-0.3434', '0.24329', '-0.19064', '-0.01752', '0.048433', '0.090054', '0.19304', '-0.14797', '0.29028', '-0.40416', '-0.41158', '-0.31941', '-0.25563', '-0.15548', '0.21389', '0.12307', '0.18555', '-0.1319', '-0.063817', '-0.053527', '0.46211', '0.30172', '0.020599', '0.29715', '-0.13042', '-0.16117', '-0.23458', '0.16125', '-0.01119', '0.15315', '-0.35568', '-0.10407', '-0.21056', '-0.34712', '0.068152', '-0.22672', '0.26074', '-0.078383', '-0.10993', '0.051198', '0.17166', '0.38801', '-0.23081', '-0.45485', '-0.3261', '0.29937', '-0.13044', '-0.21967', '0.089537', '-0.1708', '-0.11706', '-0.25279', '0.17708', '-0.24861', '0.031159', '0.13719', '-0.025041', '0.19073', '0.1498', '-0.060723', '0.03451', '-0.31148', '-0.099856', '0.10595', '0.057785', '0.035898', '0.34743', '0.46267', '0.19064', '-0.29399', '-0.034044', '-0.00202', '-0.11221', '0.081553', '-0.028337', '0.027133', '0.06194', '-0.20779', '0.040717', '0.22114', '-0.033452', '0.096417', '-0.15576', '0.092885', '0.10953', '0.30876', '-0.046338', '0.026886', '0.0090883', '-0.33831', '0.25082', '-0.32224', '-0.084438', '0.0032345', '0.3716', '-0.3636', '0.056198', '0.14221', '0.43704', '-0.29346', '-0.071472', '-0.13171', '-0.027294', '0.061764', '0.48544', '0.21806', '0.039758', '0.24481', '-0.19782', '0.18957', '0.011929', '-0.029168', '-0.18087', '-0.061977', '0.31739', '0.28306', '-0.049168', '0.20288', '0.13088', '0.042424', '-0.018599', '0.22127', '-0.088954', '0.2308', '-0.096051', '-0.20645', '-0.025959', '0.072446', '-0.030101', '0.044369', '-0.06798', '0.078235', '-0.020235', '0.072565', '-0.091731', '-0.17504', '0.14923', '0.08272', '0.4292', '-0.16034', '0.1136', '-0.31294', '0.051864', '-0.24166', '0.12065', '-0.1104', '0.072212', '-0.44531', '0.078985', '-0.17171', '0.19141', '-0.1289', '-0.071916', '-0.18034', '-0.25264', '-0.10075', '0.2103', '0.22964', '-0.1331', '-0.11915', '0.12331', '-0.19272', '-0.3762', '0.25084', '0.0084705', '0.04884', '-0.20073', '0.098775', '-0.085074', '-0.25098', '0.24722', '0.069073', '-0.28087', '0.26715', '-0.17698', '0.31071', '-0.085727', '-0.11678', '-0.028596', '0.046765', '0.045766', '0.010138', '-0.24704', '-0.066645', '-0.34908', '0.21954', '-0.033994', '-0.04225', '0.18116', '0.18716', '-0.12065', '0.019134', '0.073161', '0.30922', '-0.11741', '-0.11892', '-0.15525', '-0.54939', '-0.25133', '-0.022141', '0.25535', '0.02956', '-0.11286', '-0.013508', '-0.19382', '-0.47838', '-0.078225', '-0.087933', '0.14154', '0.21634', '0.013367', '-0.041105', '0.23293', '0.058377', '-0.51906', '-0.24025', '0.16657', '-0.3006', '0.45285', '-0.060122', '-0.20118', '0.049305', '-0.039655', '-0.33169', '0.033918', '-0.15622', '-0.13579', '0.16999', '0.10184', '-0.26241']\n",
      "['ku', 'ni', '-0.082634', '0.095467', '-0.0023787', '-0.26767', '-0.019017', '0.12699', '-0.08894', '-0.30361', '0.023513', '0.13042', '-0.10522', '-0.049791', '0.026414', '0.13299', '0.27489', '0.33267', '0.31635', '-0.1594', '-0.24824', '0.1561', '0.13721', '0.076647', '0.31607', '-0.28405', '-0.21418', '0.16121', '0.093978', '0.0063017', '0.031736', '0.17479', '0.2256', '0.39949', '-0.072433', '-0.26707', '-0.056918', '0.42312', '-0.60316', '-0.08073', '0.095283', '-0.50697', '-0.034953', '-0.38553', '0.061729', '-0.049352', '-0.085847', '0.22417', '-0.073336', '0.018507', '-0.12166', '0.10973', '0.13321', '-0.096938', '-0.012908', '-0.066115', '-0.046424', '-0.02684', '0.36098', '-0.24993', '0.30432', '-0.10505', '0.18475', '0.44154', '-0.32452', '0.1892', '-0.27833', '0.1995', '0.15079', '0.54364', '-0.10571', '0.37236', '0.074662', '0.04452', '0.084651', '0.0514', '-0.017389', '-0.12939', '0.047071', '-0.10044', '0.041842', '-0.12051', '-0.0786', '-0.10266', '-0.44598', '0.047608', '0.14771', '0.14676', '-0.21365', '0.36534', '0.054687', '-0.42506', '0.26206', '-0.080276', '-0.11108', '0.094423', '-0.32689', '-0.31889', '-0.12625', '-0.30771', '0.26918', '0.41237', '-0.31256', '-0.37466', '0.063441', '-0.023082', '-0.11973', '-0.0030649', '0.3051', '-0.10459', '0.13333', '-0.096567', '0.024381', '0.24822', '-0.21243', '-0.044166', '-0.054709', '0.06308', '0.29878', '0.031563', '0.30525', '-0.54491', '-0.076095', '-0.059521', '-0.021245', '-0.019546', '-0.00014914', '-0.34811', '0.015466', '0.045123', '0.2556', '0.53001', '0.02316', '0.32567', '-0.34295', '0.092106', '0.15511', '0.047821', '-0.21793', '-0.24599', '-0.50357', '-0.16704', '0.047562', '-0.040246', '0.10975', '0.25314', '-0.027346', '0.18068', '-0.034374', '-0.21539', '-0.0245', '-0.15728', '-0.31795', '-0.067549', '0.13419', '0.086604', '0.14587', '-0.17201', '-0.051791', '0.063892', '0.078862', '0.10353', '0.11963', '0.23897', '-0.21696', '-0.05612', '-0.056535', '-0.14487', '-0.28218', '0.25395', '-0.043539', '0.14587', '-0.091372', '0.052001', '-0.020114', '-0.20983', '-0.1422', '0.26949', '0.069673', '-0.33383', '0.053605', '-0.010035', '-0.031829', '0.14834', '-0.07218', '-0.1473', '-0.097343', '0.12487', '-0.28909', '-0.11877', '-0.18675', '0.20279', '0.083171', '0.070787', '0.014053', '-0.36102', '0.32837', '-0.11821', '0.18666', '-0.039712', '-0.12546', '-0.22615', '-0.12534', '0.060035', '0.11852', '-0.19514', '0.57262', '0.32808', '-0.063024', '0.13134', '-0.13837', '-0.023665', '0.27844', '0.070516', '0.19881', '0.1666', '-0.059498', '-0.052216', '-0.14527', '-0.050985', '0.20701', '0.45533', '-0.30542', '0.37773', '0.021121', '-0.3627', '0.24221', '0.16276', '0.063599', '0.014625', '0.061299', '-0.22913', '0.15589', '0.066959', '0.088397', '-0.075367', '0.080976', '0.19064', '0.05566', '0.0028399', '-0.074259', '0.10108', '0.044001', '-0.43047', '-0.076756', '0.33433', '-0.094086', '-0.13427', '-0.051266', '-0.23285', '0.042794', '0.24145', '0.2118', '0.26496', '0.19823', '-0.040545', '-0.12712', '-0.015516', '-0.18744', '-0.061298', '-0.28757', '0.17917', '-0.23271', '-0.017259', '0.057239', '-0.47221', '0.04963', '-0.19907', '0.12505', '-0.041226', '-0.19625', '0.023553', '0.043381', '0.17677', '0.090303', '0.071312', '-0.0013008', '-0.22446', '0.080477', '-0.32237', '0.22726', '-0.06271', '0.12972', '0.085193', '0.33518', '-0.088804', '-0.055492', '0.033864', '-0.12823', '0.11423', '0.11527', '0.13356', '0.11363', '0.042889', '-0.07278', '-0.057368', '-0.050021', '-0.025637', '0.2257', '-0.053105', '0.084793', '0.042313', '0.0062681', '-0.21467', '0.36325', '0.16453', '-0.17198', '0.33131', '-0.029672', '-0.068433', '0.16635', '-0.036476', '0.29194', '-0.19678', '0.11271', '0.16585', '-0.0047122', '-0.43003', '-0.33271', '0.078583', '-0.12683', '-0.21346', '0.002936', '-0.3359', '-0.12607', '-0.03494', '0.047911', '-0.28978', '0.017068', '-0.24588', '0.21604', '-0.070596', '0.072165', '-0.034059', '-0.19553', '-0.033652', '-0.18688', '0.6212', '-0.15578', '-0.070615', '0.025117', '-0.13293', '0.19286', '0.054051', '-0.057731', '0.2339', '-0.21625', '0.32767', '-0.11039', '0.041853', '0.34946', '0.29134', '0.15753', '-0.38683', '0.43342', '-0.10127', '0.19839', '-0.015648', '-0.35287', '-0.10719', '-0.13594', '-0.31305', '-0.31559', '0.15478', '-0.04022', '0.2084', '-0.085186', '0.12436', '-0.29767', '0.045219', '-0.11762', '0.43235', '0.49862', '0.12023', '-0.063773', '-0.43245', '-0.13196', '0.045433', '0.21414', '-0.03146', '0.16661', '0.15638', '-0.028099', '-0.20187', '-0.0080505', '-0.13101', '-0.002022', '-0.23877', '0.30455', '0.016962', '-0.13583', '0.044305', '-0.52322', '-0.02693', '-0.17082', '-0.32194', '-0.096032', '-0.14243', '0.011025', '0.065656', '-0.047114', '0.29189', '-0.22717', '0.18451', '-0.30661', '-0.022325', '0.16307', '0.19643', '-0.030484', '0.077006', '0.39047', '0.08277', '0.07154', '0.55865', '0.13443', '0.21279', '-0.034246', '-0.18065', '0.55816', '-0.02029', '-0.15426', '0.16059', '0.05175', '0.045762', '-0.043524', '-0.34502', '-0.29157', '-0.17915', '0.0020102', '-0.17678', '0.071854', '-0.047353', '0.023815', '-0.26862', '0.12394', '-0.021398', '-0.068155', '-0.12215', '0.019239', '-0.49207', '0.25597', '-0.027844', '0.19639', '0.018782', '-0.059749', '-0.39146', '-0.15292', '-0.17733', '-0.14007', '-0.054961', '0.037559', '0.38388', '-0.13875', '-0.090546', '-0.16952', '-0.2388', '0.19805', '0.18333', '-0.0017357', '0.083621', '-0.03953', '-0.049325', '0.047025', '0.14352', '0.10331', '0.27054', '0.45567', '0.041099', '-0.25076', '-0.021759', '0.085312', '0.016965', '0.092444', '0.026433', '-0.31154', '-0.096822', '-0.27405', '0.093031', '-0.26824', '0.15009', '-0.50841', '-0.034002', '-0.10724', '-0.33763', '-0.24152', '-0.026763', '0.0088204', '-0.068496', '-0.10828', '-0.28813', '0.064673', '-0.12481', '-0.2127', '0.10311', '0.20542', '0.060933', '-0.091719', '-0.040462', '-0.37217', '-0.061398', '0.25039', '0.13357', '0.2048', '0.10692', '-0.084079', '-0.10251', '-0.16056', '0.24939', '-0.16025', '-0.43324', '0.10354', '0.20843', '-0.0008306', '-0.056103']\n",
      "['to', 'tọwọ', '0.0076001', '0.28251', '-0.04743', '-0.36416', '0.24173', '-0.057931', '-0.19147', '-0.39249', '-0.040719', '0.054955', '0.14375', '0.14733', '-0.11364', '0.14393', '0.25268', '0.2795', '0.19564', '0.046206', '-0.15659', '0.026766', '0.077632', '-0.097959', '0.26887', '0.10829', '-0.37551', '0.15423', '0.18712', '0.10648', '0.044963', '0.013205', '0.17509', '0.28641', '-0.29889', '-0.27236', '0.1151', '0.37888', '-0.58205', '0.081479', '-0.076253', '-0.46297', '-0.13683', '-0.28781', '-0.028264', '-0.0897', '0.0021597', '0.32263', '-0.11694', '-0.0040963', '-0.021167', '0.30539', '-0.041117', '0.18253', '-0.03428', '-0.095832', '0.001266', '-0.2512', '0.41736', '-0.22965', '0.48245', '-0.077942', '0.19169', '0.10406', '-0.25503', '0.030338', '-0.13766', '0.42933', '0.11571', '0.29432', '0.16231', '0.18461', '0.20496', '0.098999', '0.050035', '0.29012', '-0.11988', '-0.0083059', '-0.012114', '-0.26546', '-0.021117', '-0.11326', '-0.079938', '-0.079321', '-0.38724', '-0.039184', '-0.0019342', '0.055719', '-0.17119', '0.017719', '0.031862', '-0.44656', '0.27067', '0.1423', '0.033319', '0.24168', '-0.2968', '-0.015333', '0.073132', '-0.22743', '0.1365', '0.22751', '-0.19051', '-0.52156', '0.089244', '0.080676', '0.019948', '0.15937', '0.17274', '-0.029418', '0.18633', '-0.3161', '-0.027441', '0.032797', '0.076103', '-0.12851', '-0.14689', '0.013051', '0.45346', '0.052189', '0.22109', '-0.47974', '0.11367', '-0.26611', '0.23103', '-0.093733', '-0.068787', '-0.33172', '0.032149', '0.18518', '0.14641', '0.31778', '0.15819', '0.057043', '-0.26824', '0.089258', '-0.017312', '0.2344', '-0.24277', '-0.19291', '-0.15697', '-0.029668', '0.035445', '-0.17533', '0.21886', '0.29367', '-0.14995', '-0.019357', '0.10586', '-0.07885', '0.22418', '-0.01593', '-0.14465', '-0.023538', '0.24664', '-0.066917', '0.14769', '-0.11622', '-0.053905', '0.22874', '0.087669', '0.060871', '0.17671', '0.28751', '-0.21829', '-0.1362', '0.10916', '-0.16749', '0.057628', '0.22456', '-0.16935', '0.28835', '-0.23344', '-0.048646', '-0.18191', '-0.12413', '-0.16265', '-0.009156', '-0.20274', '-0.2661', '0.046397', '0.33635', '-0.1471', '0.32461', '-0.21652', '-0.39383', '-0.20189', '0.23849', '-0.25978', '-0.18058', '0.016833', '0.26504', '0.12715', '0.13764', '0.071073', '-0.22412', '0.38606', '-0.00056442', '0.14882', '-0.10283', '0.10545', '-0.33091', '-0.22409', '0.15174', '-0.077013', '-0.25119', '0.34283', '0.34301', '-0.34058', '-0.04249', '0.14536', '0.014461', '0.3682', '-0.052546', '-0.012797', '0.18044', '-0.039421', '-0.12937', '0.026718', '-0.015224', '0.014518', '0.47559', '-0.056712', '0.40663', '-0.091567', '-0.61232', '0.12134', '0.05713', '0.066425', '0.0079425', '0.22637', '-0.2314', '0.15879', '0.09807', '0.31593', '0.03822', '-0.10551', '0.16006', '0.032774', '-0.070794', '-0.30585', '0.16726', '0.009978', '-0.16728', '-0.21565', '0.47766', '-0.062385', '-0.42082', '-0.014545', '-0.1884', '-0.0087635', '0.13939', '0.22738', '0.065516', '0.26857', '-0.10865', '-0.063637', '0.069135', '-0.19753', '-0.34189', '-0.28241', '-0.036534', '-0.053284', '0.10025', '0.20091', '-0.33384', '0.19573', '-0.010514', '0.12451', '-0.18949', '0.043351', '0.20301', '0.28113', '-0.069497', '-0.0038244', '0.096027', '0.009615', '-0.027077', '0.18394', '-0.12085', '0.077321', '0.19068', '0.15067', '0.33485', '0.19601', '-0.05658', '-0.0062857', '0.085321', '0.13752', '-0.13427', '-0.061576', '0.40012', '0.086812', '0.10601', '0.014565', '-0.17484', '0.050167', '-0.013591', '0.15773', '-0.0067219', '0.1394', '-0.12464', '-0.09992', '-0.27719', '0.1352', '0.10634', '-0.19405', '0.38772', '-0.024979', '-0.26358', '-0.11972', '0.19854', '0.20087', '-0.31517', '-0.14348', '-0.0011', '0.020187', '-0.11794', '-0.36363', '0.068417', '0.096335', '-0.25474', '-0.14169', '-0.41349', '-0.047927', '-0.026463', '0.0085083', '-0.40678', '-0.022874', '-0.075416', '0.20649', '-0.36785', '0.10869', '0.068939', '-0.087219', '-0.086883', '-0.088017', '0.26051', '-0.16656', '0.048684', '-0.096713', '-0.10188', '0.61515', '0.31904', '0.013422', '0.053414', '-0.18069', '0.29525', '-0.39395', '0.045404', '0.31125', '0.15126', '0.0037034', '-0.42996', '0.37669', '-0.025032', '0.073887', '-0.080987', '-0.18735', '-0.16978', '-0.12754', '-0.35567', '-0.35153', '0.18876', '-0.19203', '-0.034772', '0.2111', '-0.17444', '0.085098', '0.13136', '-0.35022', '0.21091', '0.27137', '0.2343', '0.034368', '-0.36511', '-0.14099', '-0.12651', '0.3745', '0.057146', '0.33085', '0.23496', '-0.2176', '-0.066492', '-0.082067', '-0.22656', '0.11614', '-0.0042154', '-0.063575', '-0.21557', '-0.17453', '0.14908', '-0.3669', '-0.19278', '-0.032351', '-0.48806', '-0.2024', '-0.19739', '-0.084773', '-0.013068', '0.10852', '0.17215', '-0.061331', '0.14956', '-0.40764', '-0.109', '0.24312', '0.0097767', '-0.18734', '0.10397', '0.31538', '0.28152', '0.16909', '0.6713', '0.1148', '0.31841', '-0.1343', '-0.11245', '0.46594', '0.23554', '0.0076938', '0.094238', '0.15243', '0.042115', '-0.19535', '-0.46922', '-0.071866', '-0.14372', '-0.049868', '-0.1522', '0.0048332', '0.24387', '-0.001374', '-0.10634', '0.083871', '0.18142', '-0.089328', '-0.13961', '0.076489', '-0.12754', '0.10144', '0.11478', '0.12655', '0.017993', '-0.28923', '-0.28537', '0.048232', '-0.10843', '-0.14184', '0.016681', '-0.10458', '0.36875', '-0.32305', '-0.082249', '0.032161', '-0.19594', '0.017025', '0.19117', '0.066478', '0.15839', '-0.0632', '0.14446', '-0.0047048', '-0.21052', '0.20788', '0.080151', '0.13887', '0.20797', '-0.26856', '0.063376', '0.024739', '0.043778', '0.031895', '0.17553', '-0.22091', '-0.14901', '-0.21681', '0.15052', '-0.36507', '0.26756', '-0.45025', '-0.25376', '-0.14081', '-0.17811', '-0.20717', '-0.10151', '0.031659', '0.020589', '-0.043952', '-0.48292', '-0.056664', '-0.048387', '-0.096132', '-0.037812', '0.17701', '0.023092', '-0.19034', '-0.083669', '-0.1731', '-0.18822', '-0.036479', '-0.043033', '0.0065009', '-0.008534', '0.020719', '-0.008731', '0.045103', '0.17114', '-0.0059032', '-0.4186', '0.045088', '-0.25758', '0.02237', '-0.2777']\n",
      "['”', 'Aare', '0.21017', '-0.20173', '-0.025152', '-0.15223', '-0.083918', '-0.29161', '-0.08834', '0.021089', '-0.3197', '0.16532', '0.020846', '0.010466', '0.1566', '-0.037831', '0.28484', '0.24848', '0.49356', '0.037101', '-0.36636', '-0.056494', '-0.11274', '-0.15979', '0.4393', '-0.21961', '-0.14755', '-0.15168', '-0.15995', '0.03008', '0.078575', '-0.03093', '0.068799', '0.26714', '-0.20525', '-0.040767', '0.18805', '0.30654', '-0.28095', '0.073831', '0.14363', '-0.36601', '-0.093695', '-0.069134', '-0.15809', '-0.13507', '-0.24738', '0.4369', '-0.2938', '0.21014', '0.044579', '-0.12174', '-0.049056', '-0.0011425', '-0.09825', '-0.15667', '-0.1165', '-0.0021355', '0.0029162', '0.37699', '0.23095', '0.015032', '0.14626', '0.28363', '-0.05708', '0.19233', '-0.23627', '0.32558', '0.23151', '-0.047505', '-0.21339', '0.048355', '0.12246', '0.065416', '-0.10099', '-0.046532', '-0.2782', '0.032564', '0.42824', '-0.12918', '0.044821', '0.022309', '-0.080611', '-0.10955', '-0.084527', '-0.011163', '0.15471', '0.043663', '0.15052', '0.23019', '0.093767', '-0.42488', '0.26916', '-0.14387', '-0.059544', '-0.024961', '0.087741', '-0.062065', '0.24854', '-0.24752', '0.21494', '0.20503', '0.07282', '-0.132', '0.09896', '-0.26387', '-0.20637', '0.14455', '0.11125', '0.16613', '-0.23978', '-0.01222', '-0.21677', '0.086618', '-0.0029478', '0.19785', '0.094371', '0.017941', '-0.050323', '-0.032845', '-0.070864', '-0.26147', '0.15314', '-0.23167', '0.28446', '-0.046636', '-0.21952', '-0.011623', '0.049327', '-0.16327', '-0.031904', '0.26419', '0.052074', '0.27429', '-0.32374', '0.24683', '-0.15226', '0.15844', '-0.14569', '0.031337', '0.17787', '0.047125', '0.12771', '-0.13687', '0.31506', '0.094654', '0.0054081', '0.19279', '0.073131', '0.038438', '7.1613e-05', '-0.16119', '-0.07153', '0.076721', '-0.031846', '0.2084', '0.26747', '0.2019', '-0.090463', '-0.10056', '0.10704', '0.092912', '0.064398', '0.018213', '-0.17238', '-0.42692', '0.14219', '-0.049525', '0.077605', '0.11103', '-0.28036', '0.02457', '0.0064209', '-0.065027', '-0.26184', '-0.111', '-0.20536', '-0.21634', '0.13731', '-0.070502', '-0.057749', '-0.062001', '-0.21306', '0.24114', '-0.11073', '-0.42366', '0.1446', '0.17282', '-0.16926', '0.12306', '-0.077117', '0.37539', '0.02819', '-0.039558', '-0.0063652', '0.23633', '0.10037', '0.066735', '0.24655', '0.13578', '-0.10561', '-0.021041', '-0.20498', '-0.12028', '0.13673', '-0.17364', '-0.17229', '0.13241', '-0.11399', '0.093551', '0.14454', '-0.32451', '0.13199', '0.029294', '0.19798', '-0.081545', '0.10876', '0.18209', '0.14849', '-0.13489', '0.029603', '0.0061988', '0.027356', '0.078018', '-0.084984', '-0.29903', '-0.15892', '0.12419', '-0.063754', '0.12726', '0.051606', '0.01134', '0.23576', '0.083897', '0.33781', '0.084373', '-0.050611', '0.14272', '0.23327', '-0.14314', '-0.067702', '0.32891', '0.21595', '0.027716', '-0.0089177', '0.25353', '0.00028334', '0.16533', '-0.022547', '-0.2368', '-0.14252', '-0.053706', '-0.087926', '0.21557', '0.078546', '-0.1102', '0.061177', '0.31583', '-0.0092208', '-0.14119', '-0.085796', '0.057013', '-0.16862', '0.015798', '-0.11083', '-0.19102', '0.067996', '0.41079', '-0.0046241', '-0.3991', '-0.12715', '0.025418', '-0.11726', '0.30579', '0.29781', '-0.012043', '-0.18633', '-0.093065', '-0.080497', '-0.2008', '0.069455', '-0.09037', '0.068535', '-0.061032', '0.25536', '0.19242', '-0.083109', '-0.028581', '0.1334', '-0.28891', '0.12459', '0.23438', '-0.1152', '0.055265', '0.081643', '-0.12011', '-0.37653', '-0.10234', '-0.098756', '0.016036', '-0.086664', '-0.013898', '-0.11402', '-0.25579', '0.20631', '0.18936', '0.049532', '0.054542', '0.065856', '0.14664', '0.03873', '-0.027518', '0.0079993', '0.2552', '0.031003', '0.18283', '-0.016406', '0.072572', '-0.19624', '0.19464', '0.28596', '-0.011646', '0.15132', '-0.44102', '-0.12317', '-0.020662', '0.0039127', '-0.27628', '-0.27431', '-0.23119', '0.30705', '-0.34631', '-0.12821', '0.17906', '0.1587', '-0.015597', '-0.040124', '0.17932', '-0.045399', '0.023385', '-0.10427', '-0.25313', '0.2912', '-0.068927', '-0.017044', '0.090539', '-0.29306', '0.30865', '-0.11134', '0.069445', '-0.080133', '0.46319', '-0.0067481', '-0.38565', '-0.083403', '0.054545', '-0.06623', '0.21332', '0.16625', '0.084241', '-0.025332', '-0.167', '-0.29053', '0.12619', '-0.17191', '0.26676', '0.1619', '-0.09579', '-0.51432', '0.030779', '-0.12894', '0.42361', '0.079979', '0.067688', '-0.010367', '-0.061512', '0.04155', '-0.11921', '0.14294', '-0.14224', '-0.1193', '0.099665', '-0.067713', '0.084731', '-0.013333', '-0.11664', '-0.26482', '-0.039658', '0.28342', '-0.4709', '-0.28057', '0.32656', '-0.19041', '0.085151', '-0.085935', '-0.45797', '-0.036315', '-0.045895', '0.049666', '0.20966', '-0.12583', '0.26655', '-0.049419', '-0.077227', '-0.23342', '0.15021', '-0.047507', '0.21574', '-0.27224', '-0.037125', '0.18871', '-0.072123', '-0.23262', '0.12229', '0.077722', '-0.23757', '0.17428', '0.19108', '0.25647', '0.031833', '-0.14051', '-0.22365', '0.015407', '-0.056611', '0.33771', '-0.039688', '-0.1884', '-0.086952', '-0.34565', '-0.063828', '-0.24188', '-0.05338', '-0.22938', '-0.29908', '-0.0037044', '0.099575', '0.12225', '-0.045541', '0.085394', '-0.28138', '0.396', '0.15631', '0.19637', '0.29669', '-0.036148', '-0.20424', '-0.35504', '-0.044869', '0.12306', '0.064792', '0.39831', '0.20002', '-0.29288', '-0.25517', '0.079697', '-0.072534', '-0.054613', '0.12626', '-0.15615', '0.15608', '-0.15938', '-0.43604', '-0.088543', '0.14699', '0.099608', '0.16279', '0.042397', '0.085634', '-0.48459', '-0.13705', '-0.058702', '0.17267', '0.054719', '0.21344', '0.017247', '-0.014103', '-0.23372', '-0.16393', '-0.19549', '0.24708', '-0.48912', '-0.33173', '-0.19777', '-0.24962', '-0.272', '0.024165', '-0.3159', '0.42744', '-0.20918', '-0.14565', '0.33927', '-0.085164', '-0.088611', '0.21027', '0.11731', '0.26837', '-0.1706', '-0.25621', '-0.12784', '-0.38101', '0.42875', '-0.19401', '0.12171', '-0.055607', '0.096581', '-0.092208', '0.0049512', '-0.32525', '0.25965', '-0.30677', '-0.0266', '0.1738', '0.043042', '-0.13708']\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastTextModel(file_path='embeddings/afriberta/afriberta.vec')\n",
    "class FastTextTokenizer:\n",
    "\n",
    "    def __init__(self, word2id):\n",
    "        self.word2id = word2id\n",
    "        \n",
    "    def __call__(self, texts, **kwargs):\n",
    "        tokens = []\n",
    "        for text in texts:\n",
    "            text_tokens = []\n",
    "            for word in text.split():\n",
    "                if word in self.word2id:\n",
    "                    text_tokens.append(self.word2id[word])\n",
    "                else:\n",
    "                    text_tokens.append(self.word2id['<unk>'])\n",
    "            tokens.append(text_tokens)\n",
    "        return tokens\n",
    "\n",
    "fasttext_tokenizer = FastTextTokenizer(fasttext_model.word2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d6f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105862 rows from sentiment.parquet columns Index(['text', 'label', 'lang', 'split'], dtype='object')\n",
      "train shape: (2800, 4), test shape: (700, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552069/3998590600.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sent_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30809 rows from masakhanews.parquet columns Index(['label', 'headline', 'text', 'headline_text', 'url', 'lang', 'split'], dtype='object')\n",
      "train shape: (3200, 7), test shape: (800, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552069/3998590600.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  news_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18375fdd43c949b5a60e2a033d341a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.45285714285714296, 0.7137500000000001, 0.2325)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pipeline(texts: list):\n",
    "    \"\"\"\n",
    "    A simple pipeline that takes a list of texts and returns their embeddings.\n",
    "    \"\"\"\n",
    "    tokens: list[list[int]] = fasttext_tokenizer(texts)\n",
    "    # Pad tokens to the longest sequence in the batch\n",
    "    max_len = min(max(len(seq) for seq in tokens), 512)  # Limit to 512 for compatibility\n",
    "    tokens = [seq[:max_len] for seq in tokens]  # Truncate sequences longer than max_len\n",
    "    pad_id = 0\n",
    "    tokens = [seq + [pad_id] * (max_len - len(seq)) for seq in tokens]\n",
    "    # print([len(seq) for seq in tokens])  # Debug: print lengths of token sequences\n",
    "    attention_mask = [[1] * len(seq) + [0] * (max_len - len(seq)) for seq in tokens]\n",
    "    \n",
    "    tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "    attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        embs = fasttext_model(tokens, attention_mask, pool=True)\n",
    "    return embs\n",
    "\n",
    "eval_model(fasttext_model, fasttext_tokenizer, pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d42461f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        embs = self.model(**kwargs).last_hidden_state\n",
    "        return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303a7dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/miniconda3/envs/py11/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at castorini/afriberta_small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1552069/3998590600.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sent_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105862 rows from sentiment.parquet columns Index(['text', 'label', 'lang', 'split'], dtype='object')\n",
      "train shape: (2800, 4), test shape: (700, 4)\n",
      "Loaded 30809 rows from masakhanews.parquet columns Index(['label', 'headline', 'text', 'headline_text', 'url', 'lang', 'split'], dtype='object')\n",
      "train shape: (3200, 7), test shape: (800, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552069/3998590600.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  news_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a74db4fe9d3463d8127d661adeb68a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.47428571428571425, 0.6525, 0.244375)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"castorini/afriberta_small\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "xmodel = AutoModel.from_pretrained(model_name)\n",
    "xmodel = Wrapper(xmodel)\n",
    "eval_model(xmodel, tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21764c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/miniconda3/envs/py11/lib/python3.11/site-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at castorini/afriberta_large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1552069/3998590600.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sent_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 105862 rows from sentiment.parquet columns Index(['text', 'label', 'lang', 'split'], dtype='object')\n",
      "train shape: (2800, 4), test shape: (700, 4)\n",
      "Loaded 30809 rows from masakhanews.parquet columns Index(['label', 'headline', 'text', 'headline_text', 'url', 'lang', 'split'], dtype='object')\n",
      "train shape: (3200, 7), test shape: (800, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1552069/3998590600.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  news_df = df.groupby('lang').apply(lambda x: x.sample(min_count, random_state=42)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacb774abf7e423782bf2bc02366bd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/3200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.4671428571428571, 0.6612500000000001, 0.285)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"castorini/afriberta_large\"\n",
    "tok = AutoTokenizer.from_pretrained(model_name)\n",
    "xmodel = AutoModel.from_pretrained(model_name)\n",
    "xmodel = Wrapper(xmodel)\n",
    "eval_model(xmodel, tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
